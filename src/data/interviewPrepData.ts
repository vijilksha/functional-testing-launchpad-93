// Complete Interview Preparation Package with all questions from all tabs
// Enhanced with STLC Agile and Agile & Jira examples and sample documents

export interface InterviewCategory {
  category: string;
  icon: string;
  description: string;
  questions: EnhancedQuestion[];
}

export interface EnhancedQuestion {
  id: string;
  question: string;
  shortAnswer: string;
  detailedAnswer: string;
  stlcAgileExample?: {
    context: string;
    realWorldScenario: string;
    sampleDocument?: string;
  };
  agileJiraExample?: {
    context: string;
    realWorldScenario: string;
    sampleDocument?: string;
  };
  tips: string[];
  commonMistakes: string[];
  followUpQuestions: string[];
  difficulty: "Beginner" | "Intermediate" | "Advanced";
}

export const interviewCategories: InterviewCategory[] = [
  {
    category: "SDLC & STLC Fundamentals",
    icon: "ğŸ”„",
    description: "Core questions about Software Development and Testing Life Cycles",
    questions: [
      {
        id: "STLC-001",
        question: "What is STLC and how does it differ from SDLC?",
        shortAnswer: "STLC is Software Testing Life Cycle - phases for testing software. SDLC is broader, covering entire software development.",
        detailedAnswer: `STLC (Software Testing Life Cycle) consists of specific phases:
1. Requirement Analysis - Understand what to test
2. Test Planning - Define strategy, resources, timeline
3. Test Case Development - Write detailed test cases
4. Environment Setup - Prepare test environment
5. Test Execution - Run tests, log defects
6. Test Cycle Closure - Final reports, lessons learned

SDLC (Software Development Life Cycle) includes:
Requirements â†’ Design â†’ Development â†’ Testing â†’ Deployment â†’ Maintenance

Key Difference: STLC is a subset focusing only on testing activities within SDLC.`,
        stlcAgileExample: {
          context: "In an Agile STLC approach, these phases happen within each sprint rather than sequentially.",
          realWorldScenario: "For an E-Commerce checkout feature, STLC phases occur during the 2-week sprint: Day 1-2 (Requirement Analysis), Day 3 (Test Planning), Day 4-6 (Test Case Development), Day 7-12 (Execution), Day 13-14 (Closure).",
          sampleDocument: `SPRINT STLC MAPPING - E-Commerce Checkout
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Sprint: Sprint 5 | Duration: 2 weeks
Feature: Shopping Cart Checkout

PHASE TIMELINE:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Day 1-2   â”‚ Requirement Analysis        â”‚
â”‚           â”‚ - Review user stories       â”‚
â”‚           â”‚ - Clarify acceptance criteriaâ”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Day 3     â”‚ Test Planning               â”‚
â”‚           â”‚ - Identify test scope       â”‚
â”‚           â”‚ - Allocate resources        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Day 4-6   â”‚ Test Case Development       â”‚
â”‚           â”‚ - Write test cases          â”‚
â”‚           â”‚ - Prepare test data         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Day 7-12  â”‚ Test Execution              â”‚
â”‚           â”‚ - Execute tests             â”‚
â”‚           â”‚ - Log and verify defects    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Day 13-14 â”‚ Test Closure                â”‚
â”‚           â”‚ - Prepare metrics report    â”‚
â”‚           â”‚ - Sprint retrospective      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
        },
        agileJiraExample: {
          context: "In Jira, STLC phases are tracked using custom workflows and issue types.",
          realWorldScenario: "Create a Test Plan issue linked to the Epic. Test Cases are sub-tasks. Use Zephyr or Xray for test management integrated with Jira.",
          sampleDocument: `JIRA STLC TRACKING SETUP
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Issue Types:
â”œâ”€â”€ Epic: User Management
â”‚   â”œâ”€â”€ Story: US-101 User Registration
â”‚   â”‚   â”œâ”€â”€ Test Plan: TP-101
â”‚   â”‚   â”œâ”€â”€ Test Case: TC-101-01
â”‚   â”‚   â”œâ”€â”€ Test Case: TC-101-02
â”‚   â”‚   â””â”€â”€ Bug: BUG-201 (linked)
â”‚   â””â”€â”€ Story: US-102 User Login
â”‚       â”œâ”€â”€ Test Plan: TP-102
â”‚       â””â”€â”€ Test Cases...

Custom Fields:
- STLC Phase: Analysis | Planning | Development | Execution | Closure
- Test Status: Not Started | In Progress | Passed | Failed | Blocked`
        },
        tips: [
          "Always relate STLC phases to specific activities in your projects",
          "Mention how phases overlap in Agile vs Waterfall",
          "Be prepared to explain entry/exit criteria for each phase"
        ],
        commonMistakes: [
          "Confusing STLC with SDLC",
          "Not mentioning all 6 phases",
          "Describing phases without real examples"
        ],
        followUpQuestions: [
          "What are entry and exit criteria for Test Execution phase?",
          "How do you handle STLC in Agile sprints?",
          "What happens if requirements change during Test Case Development?"
        ],
        difficulty: "Beginner"
      },
      {
        id: "STLC-002",
        question: "What is a Test Plan and what are its key components?",
        shortAnswer: "A Test Plan is a document outlining testing strategy, scope, approach, resources, and schedule for a project.",
        detailedAnswer: `Key components of a Test Plan:

1. **Test Plan ID** - Unique identifier
2. **Introduction** - Purpose and objectives
3. **Scope** - What's in/out of testing scope
4. **Test Items** - Features to be tested
5. **Approach/Strategy** - How testing will be performed
6. **Entry/Exit Criteria** - Start and end conditions
7. **Test Deliverables** - Documents to be produced
8. **Resources** - Team, tools, environments needed
9. **Schedule** - Timeline and milestones
10. **Risks & Mitigation** - Potential issues and solutions
11. **Approvals** - Sign-off requirements`,
        stlcAgileExample: {
          context: "In Agile, Test Plans are lightweight and created per user story or sprint rather than entire project.",
          realWorldScenario: "For a Banking Fund Transfer feature, a mini test plan covers that specific functionality within the sprint.",
          sampleDocument: `AGILE TEST PLAN - Fund Transfer Feature
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
User Story: US-301 Bank Transfer
Sprint: Sprint 8

OBJECTIVE:
Validate fund transfer between accounts works correctly 
with proper validation and error handling.

SCOPE:
âœ“ In Scope:
  - Same bank transfers
  - Inter-bank NEFT/RTGS transfers
  - Transfer validation rules
  - Transaction history update

âœ— Out of Scope:
  - International transfers
  - Scheduled transfers (future sprint)

TEST APPROACH:
- Functional testing: Positive & negative scenarios
- Security testing: Authentication, encryption
- Integration testing: Core banking API

ENTRY CRITERIA:
â–¡ User story in "Ready for Testing" status
â–¡ Test environment deployed with latest build
â–¡ Test data prepared (test accounts)
â–¡ API endpoints available

EXIT CRITERIA:
â–¡ All P1 test cases executed
â–¡ No critical or high severity bugs open
â–¡ Test coverage â‰¥ 90%
â–¡ Sign-off from Product Owner

RISKS:
| Risk | Probability | Impact | Mitigation |
|------|-------------|--------|------------|
| API instability | Medium | High | Mock services |
| Test data issues | Low | Medium | Data refresh script |`
        },
        agileJiraExample: {
          context: "Test Plans can be created as Confluence pages linked to Jira Epics/Stories, or using test management tools.",
          realWorldScenario: "Create a Test Plan in Confluence, link it to the Epic in Jira. Use Jira queries to track test case status.",
          sampleDocument: `JIRA + CONFLUENCE TEST PLAN SETUP
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

CONFLUENCE PAGE STRUCTURE:
ğŸ“„ Test Plan - Sprint 8 Fund Transfer
â”œâ”€â”€ Linked Epic: BANK-EP-005
â”œâ”€â”€ Test Scope
â”œâ”€â”€ Test Cases (embedded Jira filter)
â”œâ”€â”€ Entry/Exit Criteria
â””â”€â”€ Sign-off Section

JIRA FILTER FOR TEST TRACKING:
JQL: project = BANK AND type = "Test Case" 
     AND "Epic Link" = BANK-EP-005
     
JIRA DASHBOARD GADGETS:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test Execution Status    â”‚ Defects Open â”‚
â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘ 80% Executed â”‚ ğŸ”´ 3 Critical â”‚
â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 75% Passed   â”‚ ğŸŸ¡ 5 Major    â”‚
â”‚ â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 20% Failed   â”‚ ğŸŸ¢ 8 Minor    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
        },
        tips: [
          "Keep Agile test plans concise - 1-2 pages max",
          "Focus on what's unique for this feature, not generic content",
          "Always include entry/exit criteria - interviewers love this"
        ],
        commonMistakes: [
          "Creating overly detailed test plans in Agile",
          "Not including risk assessment",
          "Missing entry/exit criteria"
        ],
        followUpQuestions: [
          "How detailed should a test plan be in Agile?",
          "Who approves the test plan?",
          "How often do you update the test plan?"
        ],
        difficulty: "Beginner"
      },
      {
        id: "STLC-003",
        question: "Explain the difference between Test Strategy and Test Plan.",
        shortAnswer: "Test Strategy is organization-wide testing approach. Test Plan is project/feature-specific testing document.",
        detailedAnswer: `**Test Strategy:**
- High-level document
- Created once for organization/product line
- Defines overall testing approach
- Covers tools, environments, standards
- Rarely changes
- Created by Test Manager/Lead

**Test Plan:**
- Detailed document
- Created per project/release/sprint
- Specific scope, timeline, resources
- Derived from Test Strategy
- Updated frequently
- Created by Test Lead/QA

Example: Test Strategy says "Use Selenium for web automation"
Test Plan says "Sprint 5 will automate 15 login test cases using Selenium"`,
        stlcAgileExample: {
          context: "In Agile, Test Strategy is set at program level, Test Plans at sprint/story level.",
          realWorldScenario: "An Insurance company has one Test Strategy covering all products. Each sprint for Claims Processing has its own mini Test Plan.",
          sampleDocument: `STRATEGY vs PLAN COMPARISON
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

TEST STRATEGY (Organization Level):
â”œâ”€â”€ Testing Approach: Risk-based testing
â”œâ”€â”€ Tools: Selenium, JMeter, Postman
â”œâ”€â”€ Environments: Dev, QA, Staging, Prod
â”œâ”€â”€ Automation Policy: Automate regression
â”œâ”€â”€ Defect Process: Log in Jira, SLA 24hr
â””â”€â”€ Standards: IEEE 829, ISTQB guidelines

TEST PLAN (Sprint Level):
â”œâ”€â”€ Sprint: 12 - Claims Auto-Approval
â”œâ”€â”€ Scope: Auto-approve claims < $500
â”œâ”€â”€ Test Cases: 45 functional, 10 integration
â”œâ”€â”€ Resources: 2 QA engineers, 5 days
â”œâ”€â”€ Automation: 20 cases (44%)
â””â”€â”€ Timeline: 
    - Day 1-2: Test case review
    - Day 3-7: Execution
    - Day 8: Defect retesting
    - Day 9-10: Sign-off`
        },
        agileJiraExample: {
          context: "Strategy stored in Confluence wiki, Plans as sprint documents or Jira issues.",
          realWorldScenario: "Test Strategy is a Confluence space with all standards. Each sprint's Test Plan is a child page with specific details.",
          sampleDocument: `CONFLUENCE STRUCTURE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“ QA Wiki (Space)
â”œâ”€â”€ ğŸ“„ Test Strategy (Master Document)
â”‚   â”œâ”€â”€ Testing Approach
â”‚   â”œâ”€â”€ Tool Standards
â”‚   â”œâ”€â”€ Environment Strategy
â”‚   â””â”€â”€ Process Guidelines
â”‚
â”œâ”€â”€ ğŸ“ Release 2024-Q2
â”‚   â”œâ”€â”€ ğŸ“„ Test Plan - Sprint 10
â”‚   â”œâ”€â”€ ğŸ“„ Test Plan - Sprint 11
â”‚   â””â”€â”€ ğŸ“„ Test Plan - Sprint 12
â”‚
â””â”€â”€ ğŸ“ Templates
    â”œâ”€â”€ ğŸ“„ Test Plan Template
    â””â”€â”€ ğŸ“„ Test Summary Template`
        },
        tips: [
          "Strategy = What & Why, Plan = How & When",
          "Mention that Strategy is reusable, Plan is specific",
          "Be ready with examples from your experience"
        ],
        commonMistakes: [
          "Using the terms interchangeably",
          "Not understanding hierarchy (Strategy â†’ Plan)",
          "Creating too detailed Strategy or too vague Plan"
        ],
        followUpQuestions: [
          "Who creates the Test Strategy?",
          "How often is Test Strategy updated?",
          "Can you have a Test Plan without a Test Strategy?"
        ],
        difficulty: "Intermediate"
      }
    ]
  },
  {
    category: "Test Case Design & Writing",
    icon: "ğŸ“",
    description: "Questions about writing effective test cases and test design techniques",
    questions: [
      {
        id: "TC-001",
        question: "How do you write effective test cases?",
        shortAnswer: "Effective test cases are clear, concise, have defined preconditions, steps, expected results, and are traceable to requirements.",
        detailedAnswer: `Components of an effective test case:

1. **Test Case ID**: Unique identifier (e.g., TC_LOGIN_001)
2. **Title**: Brief description of what's being tested
3. **Preconditions**: Setup required before execution
4. **Test Steps**: Clear, numbered action steps
5. **Test Data**: Specific values to use
6. **Expected Result**: What should happen
7. **Priority**: P1/P2/P3 for execution order
8. **Type**: Positive/Negative/Boundary/Edge Case

Best Practices:
- One test case = one scenario
- Steps should be reproducible by anyone
- Expected result must be verifiable
- Avoid vague terms like "system works properly"`,
        stlcAgileExample: {
          context: "In Agile STLC, test cases are derived directly from acceptance criteria of user stories.",
          realWorldScenario: "For E-Commerce Add to Cart story, each acceptance criterion becomes one or more test cases.",
          sampleDocument: `TEST CASE DERIVATION FROM USER STORY
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

USER STORY: EC-US-010 Add to Cart
As a customer, I want to add products to cart
So that I can purchase multiple items

ACCEPTANCE CRITERIA â†’ TEST CASES:

AC1: "Add to cart button visible on product pages"
â”œâ”€â”€ TC_CART_001: Verify Add to Cart on product listing
â””â”€â”€ TC_CART_002: Verify Add to Cart on product detail

AC2: "Quantity can be specified before adding"
â”œâ”€â”€ TC_CART_003: Add item with default quantity (1)
â”œâ”€â”€ TC_CART_004: Add item with quantity 5
â””â”€â”€ TC_CART_005: Add item with quantity 0 (negative)

AC3: "Out of stock items cannot be added"
â”œâ”€â”€ TC_CART_006: Verify Add to Cart disabled for out of stock
â””â”€â”€ TC_CART_007: Verify message shown for out of stock

SAMPLE TEST CASE:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TC_CART_004: Add Item with Custom Quantity â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Story: EC-US-010                           â”‚
â”‚ Priority: P1 | Type: Positive              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Preconditions:                             â”‚
â”‚ - User is on product detail page           â”‚
â”‚ - Product has 10+ items in stock           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Steps:                                     â”‚
â”‚ 1. Select quantity = 5                     â”‚
â”‚ 2. Click "Add to Cart" button              â”‚
â”‚ 3. Observe cart icon                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Test Data:                                 â”‚
â”‚ Product: iPhone 15, Qty: 5                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Expected Result:                           â”‚
â”‚ - Success toast "Added to cart"            â”‚
â”‚ - Cart icon shows 5                        â”‚
â”‚ - Cart page shows iPhone 15 x 5            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
        },
        agileJiraExample: {
          context: "Test cases linked to user stories in Jira using test management plugins or sub-tasks.",
          realWorldScenario: "Each test case is a sub-task under the user story, or linked issue using Zephyr/Xray.",
          sampleDocument: `JIRA TEST CASE STRUCTURE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

EPIC: Shopping Cart (SHOP-100)
â””â”€â”€ Story: SHOP-110 Add to Cart
    â”œâ”€â”€ [Test] SHOP-110-TC01: Add single item
    â”œâ”€â”€ [Test] SHOP-110-TC02: Add with quantity
    â”œâ”€â”€ [Test] SHOP-110-TC03: Add out of stock
    â”œâ”€â”€ [Test] SHOP-110-TC04: Cart count update
    â””â”€â”€ [Bug] SHOP-BUG-045: Count not updating

TEST CASE JIRA FIELDS:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Issue Type: Test Case                   â”‚
â”‚ Summary: Add item with custom quantity  â”‚
â”‚ Story Link: SHOP-110                    â”‚
â”‚ Test Priority: P1                       â”‚
â”‚ Test Type: Functional                   â”‚
â”‚ Automation Status: To Automate          â”‚
â”‚ Execution Status: Not Executed          â”‚
â”‚                                         â”‚
â”‚ Preconditions:                          â”‚
â”‚ [Text field with setup steps]           â”‚
â”‚                                         â”‚
â”‚ Test Steps: (Using Zephyr format)       â”‚
â”‚ Step 1: Select qty=5                    â”‚
â”‚ Step 2: Click Add to Cart               â”‚
â”‚ Expected: Success message shown         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
        },
        tips: [
          "Always trace test cases to requirements",
          "Include both positive and negative scenarios",
          "Make steps detailed enough for junior testers"
        ],
        commonMistakes: [
          "Writing vague expected results",
          "Missing preconditions",
          "Combining multiple scenarios in one test case"
        ],
        followUpQuestions: [
          "How do you handle test case maintenance?",
          "What's the difference between test case and test scenario?",
          "How many test cases per requirement is ideal?"
        ],
        difficulty: "Beginner"
      },
      {
        id: "TC-002",
        question: "What are test design techniques? Explain BVA and EP.",
        shortAnswer: "Test design techniques help create effective test cases. BVA tests boundary values. EP divides data into equivalent partitions.",
        detailedAnswer: `**Boundary Value Analysis (BVA):**
Tests at the edges of input ranges where defects commonly occur.

For age field (18-60):
- Test: 17, 18, 19, 59, 60, 61

**Equivalence Partitioning (EP):**
Divides input into groups where system behaves similarly, test one from each.

For age field (18-60):
- Invalid: < 18 (test: 10)
- Valid: 18-60 (test: 35)
- Invalid: > 60 (test: 75)

Other techniques:
- Decision Table: For multiple conditions
- State Transition: For state-based systems
- Use Case Testing: Based on user scenarios`,
        stlcAgileExample: {
          context: "In Agile, apply these techniques when writing test cases from acceptance criteria.",
          realWorldScenario: "For Insurance Premium Calculator with age 25-65, use BVA and EP to ensure complete coverage.",
          sampleDocument: `TEST DESIGN - Insurance Premium Calculator
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

REQUIREMENT: Calculate premium for age 25-65

EQUIVALENCE PARTITIONING:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Invalid    â”‚  Valid       â”‚   Invalid      â”‚
â”‚ (< 25)     â”‚  (25-65)     â”‚   (> 65)       â”‚
â”‚ Test: 20   â”‚  Test: 40    â”‚   Test: 70     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

BOUNDARY VALUE ANALYSIS:
      24    25    26    ...    64    65    66
       â–²     â–²     â–²            â–²     â–²     â–²
    Invalid                           Invalid
         Valid Boundaries
         
TEST CASES DERIVED:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TC-001   â”‚ Age = 24 â†’ Error "Min age 25" â”‚
â”‚ TC-002   â”‚ Age = 25 â†’ Premium calculated â”‚
â”‚ TC-003   â”‚ Age = 26 â†’ Premium calculated â”‚
â”‚ TC-004   â”‚ Age = 40 â†’ Premium calculated â”‚
â”‚ TC-005   â”‚ Age = 64 â†’ Premium calculated â”‚
â”‚ TC-006   â”‚ Age = 65 â†’ Premium calculated â”‚
â”‚ TC-007   â”‚ Age = 66 â†’ Error "Max age 65" â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

COVERAGE ANALYSIS:
EP Coverage: 3/3 partitions (100%)
BVA Coverage: 6/6 boundaries (100%)
Total Test Cases: 7 (efficient coverage)`
        },
        agileJiraExample: {
          context: "Document test design technique in test case description for traceability.",
          realWorldScenario: "Add custom field 'Design Technique' to track which technique generated the test case.",
          sampleDocument: `JIRA CUSTOM FIELDS FOR DESIGN TECHNIQUES
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

TEST CASE: Age Validation - Lower Boundary
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Design Technique: BVA (Lower Boundary)  â”‚
â”‚ Related Requirement: Premium Calculator â”‚
â”‚                                         â”‚
â”‚ Test Data:                              â”‚
â”‚ Age: 25 (minimum valid boundary)        â”‚
â”‚                                         â”‚
â”‚ Expected: Premium = $150/month          â”‚
â”‚                                         â”‚
â”‚ Labels: BVA, Boundary, Positive         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

JQL FOR TECHNIQUE COVERAGE:
"Design Technique" = BVA AND project = INS
â†’ Returns all BVA-based test cases`
        },
        tips: [
          "Always combine BVA and EP for better coverage",
          "Mention specific examples with numbers",
          "Know when to use each technique"
        ],
        commonMistakes: [
          "Only testing middle values, missing boundaries",
          "Testing all values in a partition (defeats EP purpose)",
          "Not considering negative/positive boundaries"
        ],
        followUpQuestions: [
          "How many boundary values should you test?",
          "What if there are multiple input fields?",
          "How do you apply BVA to non-numeric fields?"
        ],
        difficulty: "Intermediate"
      }
    ]
  },
  {
    category: "Agile & Scrum Testing",
    icon: "ğŸ”",
    description: "Questions about testing in Agile environment",
    questions: [
      {
        id: "AGILE-001",
        question: "What are the key Scrum ceremonies and tester's role in each?",
        shortAnswer: "Sprint Planning, Daily Standup, Sprint Review, Retrospective. Testers participate in all, providing testing perspective.",
        detailedAnswer: `**1. Sprint Planning:**
- Tester Role: Review stories for testability, estimate testing effort, identify test dependencies
- Output: Test tasks added to sprint backlog

**2. Daily Stand-up:**
- Tester Role: Share testing progress, blockers, defects found
- Focus: Yesterday's testing, today's plan, any impediments

**3. Sprint Review:**
- Tester Role: Demo tested features, share quality metrics, highlight critical bugs
- Output: Stakeholder feedback on quality

**4. Sprint Retrospective:**
- Tester Role: Suggest process improvements, discuss defect patterns
- Output: Action items for better testing`,
        stlcAgileExample: {
          context: "Testers are integral part of Scrum team, not separate QA team.",
          realWorldScenario: "In a Banking app sprint, tester attends planning to flag that payment testing needs mock server setup.",
          sampleDocument: `TESTER PARTICIPATION - SPRINT CEREMONIES
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

SPRINT PLANNING (2-4 hours):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TESTER CONTRIBUTIONS:                   â”‚
â”‚ âœ“ Review acceptance criteria clarity    â”‚
â”‚ âœ“ Flag missing testability requirements â”‚
â”‚ âœ“ Estimate testing effort per story     â”‚
â”‚ âœ“ Identify test data/env needs          â”‚
â”‚ âœ“ Break down test tasks                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Example: Story "Fund Transfer"
Developer estimate: 5 points
Tester estimate: +2 points for integration testing
Final: 7 points with test tasks

DAILY STANDUP (15 min):
"Yesterday: Tested US-301, found 2 bugs
 Today: Will retest after fix, start US-302
 Blocker: Test server down since morning"

SPRINT REVIEW:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ QA Metrics Shared:                      â”‚
â”‚ â€¢ Test cases executed: 45/50 (90%)      â”‚
â”‚ â€¢ Pass rate: 42/45 (93%)                â”‚
â”‚ â€¢ Open bugs: 3 (1 Critical, 2 Medium)   â”‚
â”‚ â€¢ Automation added: 15 new tests        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

RETROSPECTIVE:
What went well: Early testing caught design issue
Improve: Need better test data management
Action: Create test data refresh script`
        },
        agileJiraExample: {
          context: "Use Jira boards and dashboards to track testing activities in ceremonies.",
          realWorldScenario: "During standup, QA opens Jira board filtered by 'In Testing' to discuss status.",
          sampleDocument: `JIRA FOR CEREMONY SUPPORT
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

SPRINT PLANNING - Story Selection View:
Filter: Sprint = "Sprint 15" AND status = "To Do"
Fields shown: Summary, Points, AC Count, Test Tasks

DAILY STANDUP - QA Quick Filters:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ My In Progress â”‚ Blocked â”‚ Done Today   â”‚
â”‚     â–ˆâ–ˆâ–ˆâ–ˆ       â”‚   â–ˆâ–ˆ    â”‚    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Filter: assignee = currentUser() 
        AND Sprint = activeSprint()
        AND status changed during -1d

SPRINT REVIEW - Dashboard Gadget:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Sprint 15 Quality Report         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Stories Tested: 8/8                     â”‚
â”‚ Test Cases: 45 Passed, 3 Failed, 2 NA   â”‚
â”‚ Bugs Found: 12 | Fixed: 10 | Open: 2    â”‚
â”‚ Automation: +15 new | 120 total         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
        },
        tips: [
          "Emphasize tester as team member, not gatekeeper",
          "Mention shift-left testing approach",
          "Be ready with examples of your ceremony participation"
        ],
        commonMistakes: [
          "Saying testing happens after development in Agile",
          "Not mentioning retrospective improvements",
          "Describing testers as separate from the team"
        ],
        followUpQuestions: [
          "How do you handle incomplete stories at sprint end?",
          "What if developers finish late, leaving no time for testing?",
          "How do you estimate testing effort in planning?"
        ],
        difficulty: "Beginner"
      },
      {
        id: "AGILE-002",
        question: "Explain the Jira issue hierarchy and when to use each level.",
        shortAnswer: "Epic > Story > Task > Sub-task > Bug. Epics for features, Stories for user requirements, Tasks for technical work.",
        detailedAnswer: `**Jira Issue Hierarchy:**

1. **Epic**: Large feature spanning multiple sprints
   - Example: "User Management System"
   
2. **Story**: User requirement delivering value
   - Example: "As a user, I want to reset password"
   
3. **Task**: Technical work within a story
   - Example: "Create password reset API"
   
4. **Sub-task**: Smaller work items
   - Example: "Write unit tests for reset API"
   
5. **Bug**: Defects found during testing
   - Example: "Reset link expires immediately"

Use the right level based on:
- Scope and complexity
- Who needs visibility
- How work is tracked/reported`,
        stlcAgileExample: {
          context: "Test activities map to different Jira levels based on scope.",
          realWorldScenario: "For Telecom billing feature: Epic for Billing System, Stories for each billing function, Sub-tasks for test cases.",
          sampleDocument: `JIRA HIERARCHY - TELECOM BILLING PROJECT
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

EPIC: TELE-EP-001 Billing & Invoicing System
â”œâ”€â”€ STORY: TELE-101 Generate Monthly Invoice
â”‚   â”œâ”€â”€ TASK: TELE-101-DEV: API development
â”‚   â”œâ”€â”€ TASK: TELE-101-TEST: Test planning
â”‚   â”‚   â”œâ”€â”€ SUB-TASK: Write test cases
â”‚   â”‚   â”œâ”€â”€ SUB-TASK: Prepare test data
â”‚   â”‚   â””â”€â”€ SUB-TASK: Execute tests
â”‚   â””â”€â”€ BUG: TELE-BUG-201: Tax calculation wrong
â”‚
â”œâ”€â”€ STORY: TELE-102 View Invoice History
â”‚   â”œâ”€â”€ TASK: TELE-102-UI: Frontend development
â”‚   â”œâ”€â”€ TASK: TELE-102-TEST: Test execution
â”‚   â””â”€â”€ BUG: TELE-BUG-202: Pagination missing
â”‚
â””â”€â”€ STORY: TELE-103 Download Invoice PDF

WHEN TO USE WHAT:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Level        â”‚ Test Use Case               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Epic         â”‚ Overall test strategy       â”‚
â”‚ Story        â”‚ Feature test plan           â”‚
â”‚ Task         â”‚ Test execution              â”‚
â”‚ Sub-task     â”‚ Individual test cases       â”‚
â”‚ Bug          â”‚ Defects found               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
        },
        agileJiraExample: {
          context: "Proper hierarchy enables reporting and traceability.",
          realWorldScenario: "Manager views Epic to see overall feature status. QA views Story to see test progress. Developer views Bug to see defects assigned.",
          sampleDocument: `JIRA REPORTING BY HIERARCHY LEVEL
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

EPIC LEVEL REPORT (For Management):
JQL: type = Epic AND project = TELE

Shows: Feature completion, Story count, Timeline

STORY LEVEL REPORT (For Product Owner):
JQL: type = Story AND "Epic Link" = TELE-EP-001

Shows: Story status, Points, Linked bugs

BUG LEVEL REPORT (For QA):
JQL: type = Bug AND Sprint = activeSprint()
     ORDER BY priority DESC

Shows: All sprint bugs by priority

DASHBOARD CONFIGURATION:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ EPIC PROGRESS          â”‚ STORIES BY STATUSâ”‚
â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘ 85%        â”‚ Done: 5          â”‚
â”‚                        â”‚ In Progress: 2   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ BUGS BY SEVERITY       â”‚ TEST COVERAGE    â”‚
â”‚ ğŸ”´ Critical: 1         â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘ 92%   â”‚
â”‚ ğŸŸ  High: 3             â”‚ 46/50 test cases â”‚
â”‚ ğŸŸ¡ Medium: 5           â”‚                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
        },
        tips: [
          "Explain with specific examples",
          "Mention how hierarchy enables reporting",
          "Know your organization's customizations"
        ],
        commonMistakes: [
          "Confusing Task with Story",
          "Creating Epics for small features",
          "Not linking bugs to stories"
        ],
        followUpQuestions: [
          "Can a Task exist without a Story?",
          "How do you handle cross-story bugs?",
          "When would you use a Spike instead of a Story?"
        ],
        difficulty: "Beginner"
      },
      {
        id: "AGILE-003",
        question: "How do you decide which test cases to automate?",
        shortAnswer: "Automate stable, repetitive, high-risk tests. Consider ROI - automation cost vs manual effort saved over time.",
        detailedAnswer: `**Criteria for Automation:**

âœ… **Good Candidates:**
- Smoke tests (run every build)
- Regression tests (run frequently)
- Data-driven tests (many combinations)
- Critical business flows
- Stable features (low change frequency)

âŒ **Avoid Automating:**
- One-time tests
- Exploratory testing
- Frequently changing UI
- Tests requiring human judgment
- Low ROI tests

**ROI Calculation:**
Automation ROI = (Manual Cost Ã— Executions) - Automation Cost
If positive, automate!

**Coverage Target:**
Typically 60-80% of regression suite automated`,
        stlcAgileExample: {
          context: "In Agile STLC, automation decisions are made during test planning and sprint automation phases.",
          realWorldScenario: "For E-commerce checkout, automate happy path and payment flows. Keep exploratory tests manual.",
          sampleDocument: `AUTOMATION DECISION MATRIX
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

E-COMMERCE CHECKOUT - AUTOMATION ANALYSIS

USER STORY: EC-US-020 Checkout Process

TEST CASE ANALYSIS:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Test Case          â”‚ Runs/Sprt â”‚ Stable?  â”‚ Complex â”‚ ROI   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ TC-001: Add to cartâ”‚    20     â”‚   Yes    â”‚   Low   â”‚ High  â”‚ âœ…
â”‚ TC-002: Valid pay  â”‚    20     â”‚   Yes    â”‚   Med   â”‚ High  â”‚ âœ…
â”‚ TC-003: Card error â”‚    10     â”‚   Yes    â”‚   Low   â”‚ High  â”‚ âœ…
â”‚ TC-004: UI layout  â”‚     5     â”‚   No     â”‚   High  â”‚ Low   â”‚ âŒ
â”‚ TC-005: Exploratoryâ”‚    N/A    â”‚   N/A    â”‚   N/A   â”‚ N/A   â”‚ âŒ
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜

ROI CALCULATION:
TC-001: Add to Cart
â”œâ”€â”€ Manual: 10 min Ã— 20 runs Ã— 12 sprints = 2400 min/year
â”œâ”€â”€ Automation: 2 hours initial + 30 min/sprint maint
â”œâ”€â”€ Automation total: 120 + (30 Ã— 12) = 480 min/year
â””â”€â”€ SAVINGS: 1920 min/year = 32 hours! âœ…

AUTOMATION RECOMMENDATION:
Automate: 3 of 5 test cases (60%)
Keep Manual: UI layout, exploratory testing`
        },
        agileJiraExample: {
          context: "Track automation status in Jira with custom fields and workflows.",
          realWorldScenario: "Add 'Automation Status' field: Manual, To Automate, Automated, Not Suitable.",
          sampleDocument: `JIRA AUTOMATION TRACKING
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

CUSTOM FIELD: Automation Status
Options:
- Manual (default)
- To Automate
- In Progress
- Automated
- Not Suitable

AUTOMATION WORKFLOW:
Manual â†’ To Automate â†’ In Progress â†’ Automated
                    â†˜ Not Suitable

DASHBOARD - AUTOMATION COVERAGE:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      SPRINT 15 AUTOMATION STATUS        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Automated    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 65%       â”‚
â”‚ To Automate  â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 15%       â”‚
â”‚ Manual       â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 15%       â”‚
â”‚ Not Suitable â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  5%       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

JQL FOR AUTOMATION BACKLOG:
"Automation Status" = "To Automate" 
AND Sprint = activeSprint()
ORDER BY priority DESC`
        },
        tips: [
          "Always mention ROI - shows business thinking",
          "Give specific automation percentages (60-80%)",
          "Know the tools and frameworks used"
        ],
        commonMistakes: [
          "Saying 'automate everything'",
          "Not considering maintenance cost",
          "Ignoring test stability before automating"
        ],
        followUpQuestions: [
          "What's your automation to manual ratio?",
          "How do you handle flaky automated tests?",
          "When would you de-automate a test?"
        ],
        difficulty: "Intermediate"
      }
    ]
  },
  {
    category: "Defect Management",
    icon: "ğŸ›",
    description: "Questions about finding, reporting, and tracking defects",
    questions: [
      {
        id: "DEF-001",
        question: "How do you write a good bug report?",
        shortAnswer: "Include title, steps to reproduce, expected vs actual result, environment, severity, priority, and attachments.",
        detailedAnswer: `**Essential Bug Report Components:**

1. **Title**: Clear, specific summary
2. **Environment**: Browser, OS, version, build
3. **Preconditions**: Setup before reproducing
4. **Steps to Reproduce**: Numbered, specific steps
5. **Actual Result**: What happened
6. **Expected Result**: What should happen
7. **Severity**: Critical/High/Medium/Low
8. **Priority**: P1/P2/P3/P4
9. **Attachments**: Screenshots, videos, logs

**Good Title Example:**
âŒ "Login not working"
âœ… "Login fails with 500 error when email contains '+' symbol"`,
        stlcAgileExample: {
          context: "In Agile, bugs are linked to stories and fixed within the same sprint if possible.",
          realWorldScenario: "Banking app fund transfer shows wrong balance - critical bug blocking story completion.",
          sampleDocument: `BUG REPORT - BANKING APPLICATION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

BUG ID: BANK-BUG-1045
TITLE: Fund Transfer Shows Incorrect Balance After Transaction

LINKED STORY: BANK-301 Fund Transfer
REPORTER: QA Analyst | DATE: 2024-01-15
SEVERITY: Critical | PRIORITY: P1

ENVIRONMENT:
â”œâ”€â”€ Application: Banking Portal v2.3.1
â”œâ”€â”€ Browser: Chrome 120.0.6099.109
â”œâ”€â”€ OS: Windows 11
â”œâ”€â”€ Test Server: qa-bank.company.com
â””â”€â”€ Test Data: Account A123, B456

PRECONDITIONS:
1. User logged in with valid credentials
2. Account A123 balance: $10,000
3. Account B456 balance: $5,000

STEPS TO REPRODUCE:
1. Navigate to Fund Transfer page
2. Select Source Account: A123
3. Select Destination Account: B456
4. Enter Amount: $500
5. Click "Transfer" button
6. Observe confirmation page

ACTUAL RESULT:
âœ— Source Account shows: $10,000 (unchanged)
âœ— Destination Account shows: $5,000 (unchanged)
âœ— Transaction appears in history
âœ— Database shows correct balances

EXPECTED RESULT:
âœ“ Source Account should show: $9,500
âœ“ Destination Account should show: $5,500
âœ“ UI should refresh with correct balances

ROOT CAUSE ANALYSIS:
UI not refreshing after API success response

ATTACHMENTS:
ğŸ“ Screenshot_balance_error.png
ğŸ“ Network_log.har
ğŸ“ Console_errors.txt`
        },
        agileJiraExample: {
          context: "Configure Jira with mandatory fields for consistent bug reporting.",
          realWorldScenario: "Jira workflow requires Environment, Steps to Reproduce before bug can be submitted.",
          sampleDocument: `JIRA BUG TEMPLATE CONFIGURATION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

PROJECT SETTINGS > ISSUE TYPES > BUG

REQUIRED FIELDS:
â”œâ”€â”€ Summary (Title)
â”œâ”€â”€ Environment (Custom Field - dropdown)
â”‚   Options: Chrome, Firefox, Safari, Mobile
â”œâ”€â”€ Steps to Reproduce (Text Area)
â”œâ”€â”€ Expected Result (Text Area)
â”œâ”€â”€ Actual Result (Text Area)
â”œâ”€â”€ Severity (Custom Field)
â”‚   Options: Critical, High, Medium, Low
â””â”€â”€ Attachments (Minimum 1 required)

OPTIONAL BUT RECOMMENDED:
â”œâ”€â”€ Affected Version
â”œâ”€â”€ Reproducibility (Always, Sometimes, Rarely)
â”œâ”€â”€ Workaround Available (Yes/No)
â””â”€â”€ Root Cause (Text - filled by dev)

AUTOMATION RULE:
IF Severity = Critical 
THEN @mention QA Lead and Dev Lead
AND set Priority = P1

SAMPLE JIRA BUG SCREEN:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ BANK-BUG-1045                           â”‚
â”‚ Fund Transfer Shows Incorrect Balance   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Type: Bug  Severity: Critical  P1       â”‚
â”‚ Status: Open  Assignee: @developer      â”‚
â”‚ Sprint: Sprint 15  Story: BANK-301      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Environment: Chrome 120 / Windows 11    â”‚
â”‚ Affected Version: 2.3.1                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Steps to Reproduce:                     â”‚
â”‚ 1. Navigate to Fund Transfer...         â”‚
â”‚ [Expand to see all]                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
        },
        tips: [
          "Always include screenshots or videos",
          "Be specific - no assumptions",
          "Distinguish severity from priority"
        ],
        commonMistakes: [
          "Vague titles like 'system crashes'",
          "Missing steps to reproduce",
          "Not providing environment details",
          "Confusing severity and priority"
        ],
        followUpQuestions: [
          "What's the difference between severity and priority?",
          "How do you handle non-reproducible bugs?",
          "What if the bug is already known?"
        ],
        difficulty: "Beginner"
      }
    ]
  },
  {
    category: "Testing Types",
    icon: "ğŸ§ª",
    description: "Questions about different types of testing",
    questions: [
      {
        id: "TYPE-001",
        question: "What is the difference between Smoke and Regression testing?",
        shortAnswer: "Smoke is quick build verification. Regression ensures new changes don't break existing functionality.",
        detailedAnswer: `**Smoke Testing:**
- Purpose: Verify build is stable enough for testing
- Scope: Critical paths only (10-20 tests)
- When: After every build deployment
- Time: 15-30 minutes
- Also called: Build Verification Testing (BVT)

**Regression Testing:**
- Purpose: Ensure new changes don't break existing features
- Scope: Comprehensive test suite (100s of tests)
- When: Before release, after major changes
- Time: Hours to days
- Often automated for efficiency

**Key Difference:**
Smoke = "Does the build work at all?"
Regression = "Does everything still work?"`,
        stlcAgileExample: {
          context: "In Agile, smoke tests run on every deployment, regression before sprint end.",
          realWorldScenario: "E-commerce site runs 15 smoke tests after each build, full 200-test regression before release.",
          sampleDocument: `SMOKE vs REGRESSION - E-COMMERCE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

SMOKE TEST SUITE (15 tests, 20 min):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ID      â”‚ Test Case            â”‚ Time   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ SM-001  â”‚ Home page loads      â”‚ 30s    â”‚
â”‚ SM-002  â”‚ User can login       â”‚ 1min   â”‚
â”‚ SM-003  â”‚ Search works         â”‚ 45s    â”‚
â”‚ SM-004  â”‚ Add to cart works    â”‚ 1min   â”‚
â”‚ SM-005  â”‚ Checkout accessible  â”‚ 45s    â”‚
â”‚ SM-006  â”‚ Payment page loads   â”‚ 1min   â”‚
â”‚ SM-007  â”‚ Order confirmation   â”‚ 1min   â”‚
â”‚ ...     â”‚ (8 more critical)    â”‚ ...    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Run: Every build | Automated: 100%

REGRESSION TEST SUITE (200 tests, 8 hours):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Module          â”‚ Tests â”‚ Auto â”‚ Manual â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ User Management â”‚   35  â”‚  28  â”‚    7   â”‚
â”‚ Product Catalog â”‚   45  â”‚  40  â”‚    5   â”‚
â”‚ Shopping Cart   â”‚   30  â”‚  25  â”‚    5   â”‚
â”‚ Checkout/Pay    â”‚   40  â”‚  30  â”‚   10   â”‚
â”‚ Order Tracking  â”‚   25  â”‚  20  â”‚    5   â”‚
â”‚ Admin Features  â”‚   25  â”‚  15  â”‚   10   â”‚
â”‚ TOTAL           â”‚  200  â”‚ 158  â”‚   42   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Run: Pre-release | Automated: 79%

EXECUTION STRATEGY:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SPRINT TIMELINE                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Day 1-7: Development (Smoke after builds)
â”‚ Day 8-10: Testing (Manual + Automation) â”‚
â”‚ Day 11-12: Regression Suite             â”‚
â”‚ Day 13: Bug fixes + Retesting           â”‚
â”‚ Day 14: Release                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
        },
        agileJiraExample: {
          context: "Track smoke and regression as test cycles or test plans in Jira.",
          realWorldScenario: "Create separate test cycles for Smoke (daily) and Regression (sprint-end).",
          sampleDocument: `JIRA TEST MANAGEMENT - ZEPHYR SETUP
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

TEST CYCLES:
â”œâ”€â”€ Smoke Test - Build 2.3.1.45
â”‚   â”œâ”€â”€ Status: Passed
â”‚   â”œâ”€â”€ Tests: 15/15 Passed
â”‚   â”œâ”€â”€ Duration: 18 min
â”‚   â””â”€â”€ Executed: 2024-01-15 14:30
â”‚
â”œâ”€â”€ Smoke Test - Build 2.3.1.46
â”‚   â”œâ”€â”€ Status: Failed
â”‚   â”œâ”€â”€ Tests: 13/15 Passed, 2 Failed
â”‚   â”œâ”€â”€ Duration: 22 min
â”‚   â””â”€â”€ Blocker: Payment page broken
â”‚
â””â”€â”€ Regression - Sprint 15 Release
    â”œâ”€â”€ Status: In Progress
    â”œâ”€â”€ Tests: 180/200 Executed
    â”œâ”€â”€ Passed: 170, Failed: 8, Blocked: 2
    â””â”€â”€ ETA: 4 hours remaining

DASHBOARD VIEW:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     SMOKE TEST TREND (LAST 7 DAYS)      â”‚
â”‚  âœ“   âœ“   âœ“   âœ“   âœ—   âœ“   âœ“             â”‚
â”‚ Mon Tue Wed Thu Fri Sat Sun             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚     REGRESSION PROGRESS                 â”‚
â”‚  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ 90%             â”‚
â”‚  180/200 executed                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
        },
        tips: [
          "Know the scope difference (critical vs comprehensive)",
          "Mention automation - both should be automated",
          "Be ready with numbers (10-20 smoke, 100+ regression)"
        ],
        commonMistakes: [
          "Saying smoke tests everything",
          "Not automating regression tests",
          "Running full regression on every build"
        ],
        followUpQuestions: [
          "How many smoke tests is ideal?",
          "Can smoke test replace regression?",
          "How do you prioritize regression tests?"
        ],
        difficulty: "Beginner"
      },
      {
        id: "TYPE-002",
        question: "What is Integration Testing and when do you perform it?",
        shortAnswer: "Testing interaction between integrated modules/components. Done after unit testing, before system testing.",
        detailedAnswer: `**Integration Testing:**
Tests how different modules work together when integrated.

**Types:**
1. **Big Bang**: Integrate all at once, test together
2. **Incremental**: Integrate and test step by step
   - Top-Down: Start from top module
   - Bottom-Up: Start from bottom module
   - Sandwich/Hybrid: Both directions

**When to Perform:**
- After unit testing of individual modules
- When modules are ready to integrate
- Before system testing

**Focus Areas:**
- Data flow between modules
- API contracts and responses
- Database interactions
- Third-party service integrations`,
        stlcAgileExample: {
          context: "In Agile, integration testing happens as features are developed and integrated.",
          realWorldScenario: "E-commerce: Test integration between Cart module and Payment Gateway API.",
          sampleDocument: `INTEGRATION TEST PLAN - CHECKOUT FLOW
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

MODULES INVOLVED:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    UI (React)                           â”‚
â”‚         â”‚                               â”‚
â”‚         â–¼                               â”‚
â”‚    Cart Service â”€â”€â–º Product Service     â”‚
â”‚         â”‚                               â”‚
â”‚         â–¼                               â”‚
â”‚    Payment Gateway (Stripe API)         â”‚
â”‚         â”‚                               â”‚
â”‚         â–¼                               â”‚
â”‚    Order Service â”€â”€â–º Notification       â”‚
â”‚         â”‚                               â”‚
â”‚         â–¼                               â”‚
â”‚    Database (PostgreSQL)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

INTEGRATION TEST CASES:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ INT-001: Cart to Payment Integration       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Verify cart data passes correctly to       â”‚
â”‚ payment gateway with amount, currency      â”‚
â”‚                                            â”‚
â”‚ Modules: Cart Service â†’ Stripe API         â”‚
â”‚                                            â”‚
â”‚ Test Data:                                 â”‚
â”‚ - Cart total: $150.00                      â”‚
â”‚ - Currency: USD                            â”‚
â”‚                                            â”‚
â”‚ Expected:                                  â”‚
â”‚ - Stripe receives exact amount             â”‚
â”‚ - Payment intent created                   â”‚
â”‚ - Client secret returned                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ INT-002: Payment to Order Integration      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Verify successful payment creates order    â”‚
â”‚ with correct details                       â”‚
â”‚                                            â”‚
â”‚ Modules: Stripe Webhook â†’ Order Service    â”‚
â”‚                                            â”‚
â”‚ Test Data:                                 â”‚
â”‚ - Payment status: succeeded                â”‚
â”‚ - Transaction ID: pi_123abc               â”‚
â”‚                                            â”‚
â”‚ Expected:                                  â”‚
â”‚ - Order created with status "Confirmed"    â”‚
â”‚ - Transaction ID stored                    â”‚
â”‚ - Confirmation email triggered             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
        },
        agileJiraExample: {
          context: "Track integration tests as separate test type in Jira.",
          realWorldScenario: "Label integration test cases with 'Integration' and link to multiple stories.",
          sampleDocument: `JIRA INTEGRATION TEST STRUCTURE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ISSUE TYPE: Test Case
LABELS: Integration, API, E2E

SAMPLE TEST CASE IN JIRA:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ INT-001: Cart to Payment Integration    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Type: Test Case                         â”‚
â”‚ Labels: Integration, API                â”‚
â”‚                                         â”‚
â”‚ Linked Stories:                         â”‚
â”‚ - SHOP-110: Add to Cart                 â”‚
â”‚ - SHOP-120: Payment Processing          â”‚
â”‚                                         â”‚
â”‚ Component: Checkout                     â”‚
â”‚ Test Level: Integration                 â”‚
â”‚ Automation: Automated (Postman)         â”‚
â”‚                                         â”‚
â”‚ Execution History:                      â”‚
â”‚ Sprint 15: âœ“ Passed                     â”‚
â”‚ Sprint 14: âœ— Failed (timeout issue)     â”‚
â”‚ Sprint 13: âœ“ Passed                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

JQL FOR INTEGRATION TESTS:
labels = Integration AND type = "Test Case"
AND project = SHOP`
        },
        tips: [
          "Know the different integration approaches",
          "Mention API testing as key integration testing",
          "Be ready to explain stubs and drivers"
        ],
        commonMistakes: [
          "Confusing with system testing",
          "Not testing error scenarios in integration",
          "Missing API contract testing"
        ],
        followUpQuestions: [
          "What's the difference between integration and system testing?",
          "How do you test when dependent service is unavailable?",
          "What tools do you use for API integration testing?"
        ],
        difficulty: "Intermediate"
      }
    ]
  },
  {
    category: "CI/CD & Automation",
    icon: "âš™ï¸",
    description: "Questions about continuous integration, delivery, and test automation",
    questions: [
      {
        id: "CICD-001",
        question: "How do you integrate automated tests into a CI/CD pipeline?",
        shortAnswer: "Configure CI tool to trigger tests on code changes. Define test stages, quality gates, and notifications.",
        detailedAnswer: `**CI/CD Test Integration Steps:**

1. **Select CI Tool**: Jenkins, GitLab CI, GitHub Actions
2. **Configure Pipeline Stages**:
   - Build â†’ Unit Tests â†’ Integration â†’ Deploy â†’ E2E
3. **Set Up Test Execution**:
   - Define test commands
   - Configure test reports
4. **Define Quality Gates**:
   - Fail build on test failure
   - Code coverage thresholds
5. **Notifications**:
   - Slack/Email on failure

**Best Practices:**
- Fast tests early (unit < 5 min)
- Parallel test execution
- Flaky test quarantine
- Test environment management`,
        stlcAgileExample: {
          context: "In Agile STLC, CI/CD integration is part of Sprint Automation phase.",
          realWorldScenario: "Insurance portal pipeline runs smoke tests on every PR, full regression nightly.",
          sampleDocument: `CI/CD PIPELINE - INSURANCE PORTAL
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

PIPELINE STAGES:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CODE PUSH                               â”‚
â”‚      â”‚                                   â”‚
â”‚      â–¼                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚  â”‚   BUILD   â”‚ â†’ Compile, Package        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚        â–¼                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚  â”‚UNIT TESTS â”‚ â†’ 100+ tests (2 min)      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚        â–¼                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚  â”‚SMOKE TESTSâ”‚ â†’ 15 critical (5 min)     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚        â–¼                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚  â”‚ DEPLOY QA â”‚ â†’ Auto-deploy to QA       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚        â–¼                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚  â”‚ API TESTS â”‚ â†’ 50 tests (10 min)       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

NIGHTLY REGRESSION (Scheduled 2 AM):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Full Regression: 200 tests (2 hours)     â”‚
â”‚ Security Scan: OWASP ZAP                 â”‚
â”‚ Performance: JMeter baseline             â”‚
â”‚ Report: Email + Slack                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

QUALITY GATES:
Gate 1: Unit tests 100% pass â†’ Proceed
Gate 2: Smoke tests pass â†’ Deploy to QA
Gate 3: Regression 95%+ â†’ Proceed to staging
Gate 4: No Critical bugs â†’ Production release

JENKINSFILE EXAMPLE:
\`\`\`groovy
pipeline {
  stages {
    stage('Build') {
      steps { sh 'mvn clean package' }
    }
    stage('Unit Tests') {
      steps { sh 'mvn test' }
      post {
        always { junit 'target/surefire-reports/*.xml' }
      }
    }
    stage('Smoke Tests') {
      steps { sh 'mvn verify -Dsuite=smoke' }
    }
    stage('Deploy QA') {
      when { branch 'develop' }
      steps { sh './deploy-qa.sh' }
    }
  }
}
\`\`\``
        },
        agileJiraExample: {
          context: "Link Jira to CI/CD for automatic status updates and build tracking.",
          realWorldScenario: "GitHub Actions updates Jira ticket status when tests pass.",
          sampleDocument: `JIRA CI/CD INTEGRATION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

GITHUB ACTIONS â†’ JIRA SYNC:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Action: On PR Merge to develop          â”‚
â”‚                                         â”‚
â”‚ 1. Run tests                            â”‚
â”‚ 2. If pass â†’ Update Jira to "Done"      â”‚
â”‚ 3. If fail â†’ Comment on Jira ticket     â”‚
â”‚ 4. Add build link to Jira               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

JIRA SMART COMMITS:
Commit: "SHOP-110 fix cart total calculation"
Result: Jira SHOP-110 gets linked commit

JIRA DASHBOARD - BUILD STATUS:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       RECENT BUILDS                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ #245 develop  âœ“ Passed   2 min ago      â”‚
â”‚ #244 feature  âœ— Failed   15 min ago     â”‚
â”‚ #243 develop  âœ“ Passed   1 hour ago     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Linked Stories: 5 updated automatically â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
        },
        tips: [
          "Know specific CI tools and their syntax",
          "Mention quality gates and thresholds",
          "Explain parallel execution for speed"
        ],
        commonMistakes: [
          "Not failing build on test failure",
          "Running slow tests on every commit",
          "No notifications for failures"
        ],
        followUpQuestions: [
          "How do you handle flaky tests in CI?",
          "What's the ideal pipeline duration?",
          "How do you manage test environments?"
        ],
        difficulty: "Advanced"
      }
    ]
  },
  {
    category: "AI in Testing",
    icon: "ğŸ¤–",
    description: "Questions about AI-powered testing tools and techniques",
    questions: [
      {
        id: "AI-001",
        question: "How is AI used in software testing?",
        shortAnswer: "AI helps with test generation, self-healing locators, visual testing, bug prediction, and test optimization.",
        detailedAnswer: `**AI Applications in Testing:**

1. **Test Case Generation**:
   - Generate tests from requirements
   - Create edge case scenarios
   - Tools: ChatGPT, TestSigma AI

2. **Self-Healing Tests**:
   - Auto-update locators when UI changes
   - Reduce maintenance
   - Tools: Testim.io, Mabl

3. **Visual Testing**:
   - Detect UI anomalies
   - Compare screenshots
   - Tools: Applitools, Percy

4. **Bug Prediction**:
   - Identify bug-prone areas
   - Prioritize testing
   - Based on code changes

5. **Test Optimization**:
   - Select relevant tests
   - Reduce execution time
   - Smart test ordering`,
        stlcAgileExample: {
          context: "AI tools integrate into Agile STLC at test design and execution phases.",
          realWorldScenario: "Use ChatGPT to generate test cases from user stories, Testim for self-healing automation.",
          sampleDocument: `AI IN AGILE TESTING WORKFLOW
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

SPRINT ACTIVITIES WITH AI:

DAY 1-2: REQUIREMENT ANALYSIS
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AI TOOL: ChatGPT                        â”‚
â”‚ PURPOSE: Generate test scenarios        â”‚
â”‚                                         â”‚
â”‚ PROMPT:                                 â”‚
â”‚ "Generate test scenarios for user       â”‚
â”‚ story: As a customer, I want to apply   â”‚
â”‚ coupon codes at checkout so I get       â”‚
â”‚ discounts. Include positive, negative,  â”‚
â”‚ and edge cases."                        â”‚
â”‚                                         â”‚
â”‚ OUTPUT: 15 test scenarios generated     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

DAY 3-6: TEST CASE DEVELOPMENT
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AI TOOL: TestSigma AI                   â”‚
â”‚ PURPOSE: Auto-generate test steps       â”‚
â”‚                                         â”‚
â”‚ INPUT: Natural language test            â”‚
â”‚ "Login and apply coupon SAVE20"         â”‚
â”‚                                         â”‚
â”‚ OUTPUT: Executable test script          â”‚
â”‚ with element identification             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

DAY 7-12: TEST EXECUTION
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AI TOOL: Testim.io                      â”‚
â”‚ PURPOSE: Self-healing automation        â”‚
â”‚                                         â”‚
â”‚ SCENARIO:                               â”‚
â”‚ Button class changed from               â”‚
â”‚ 'btn-apply' to 'coupon-apply-btn'       â”‚
â”‚                                         â”‚
â”‚ AI ACTION:                              â”‚
â”‚ âœ“ Detected locator failure              â”‚
â”‚ âœ“ Analyzed DOM for alternatives         â”‚
â”‚ âœ“ Auto-updated to new locator           â”‚
â”‚ âœ“ Test passed without manual fix        â”‚
â”‚                                         â”‚
â”‚ SAVINGS: 2 hours maintenance avoided    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
        },
        agileJiraExample: {
          context: "AI insights can be tracked and reported in Jira dashboards.",
          realWorldScenario: "Create custom fields to track AI-generated vs manual tests, AI-detected bugs.",
          sampleDocument: `JIRA AI TESTING METRICS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

CUSTOM FIELDS:
â”œâ”€â”€ Test Source: Manual | AI-Generated | Hybrid
â”œâ”€â”€ AI Tool Used: ChatGPT | Testim | Mabl
â”œâ”€â”€ Self-Healing Events: (count)
â””â”€â”€ AI Bug Detection: Yes/No

SPRINT AI INSIGHTS DASHBOARD:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     AI TESTING METRICS - SPRINT 15      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Tests by Source:                        â”‚
â”‚ â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–‘â–‘â–‘â–‘ Manual: 60 (60%)         â”‚
â”‚ â–“â–“â–“â–“â–“â–“â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ AI-Gen: 30 (30%)         â”‚
â”‚ â–“â–“â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ Hybrid: 10 (10%)         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Self-Healing Events: 23 locator fixes   â”‚
â”‚ Time Saved: ~8 hours maintenance        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ AI-Detected Bugs: 5 of 18 total (28%)   â”‚
â”‚ False Positives: 2                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

JQL FOR AI TESTS:
"Test Source" = "AI-Generated" 
AND Sprint = activeSprint()`
        },
        tips: [
          "Know specific AI testing tools",
          "Mention practical benefits (time/cost saved)",
          "Be honest about limitations"
        ],
        commonMistakes: [
          "Claiming AI can replace testers",
          "Not mentioning false positives",
          "Overhyping AI capabilities"
        ],
        followUpQuestions: [
          "What are limitations of AI testing?",
          "How do you validate AI-generated tests?",
          "Can AI do exploratory testing?"
        ],
        difficulty: "Advanced"
      }
    ]
  },
  {
    category: "Metrics & Reporting",
    icon: "ğŸ“Š",
    description: "Questions about test metrics, reports, and quality assessment",
    questions: [
      {
        id: "MET-001",
        question: "What metrics do you track during testing?",
        shortAnswer: "Test execution status, pass/fail rate, defect metrics, test coverage, and velocity in Agile.",
        detailedAnswer: `**Key Testing Metrics:**

1. **Test Execution Metrics:**
   - Tests Executed vs Planned
   - Pass Rate = Passed / Total Executed
   - Blocked/Skipped count

2. **Defect Metrics:**
   - Defects Found vs Fixed
   - Severity Distribution
   - Defect Density = Bugs / KLOC
   - Defect Leakage to Prod

3. **Coverage Metrics:**
   - Requirement Coverage
   - Code Coverage (for automation)

4. **Agile Metrics:**
   - Velocity (story points completed)
   - Sprint Burndown
   - Escaped Defects

5. **Automation Metrics:**
   - Automation Coverage %
   - Automation ROI`,
        stlcAgileExample: {
          context: "In Agile STLC, metrics are reviewed daily and during sprint review.",
          realWorldScenario: "Banking app sprint tracks test pass rate, defects by severity, and automation coverage.",
          sampleDocument: `SPRINT TEST METRICS REPORT
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

PROJECT: Banking Portal | SPRINT: 15
PERIOD: Jan 1-14, 2024

TEST EXECUTION SUMMARY:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Metric          â”‚ Value  â”‚ Target  â”‚ âœ“/âœ—â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Total Planned   â”‚ 120    â”‚ 120     â”‚ âœ“  â”‚
â”‚ Executed        â”‚ 115    â”‚ 120     â”‚ âœ—  â”‚
â”‚ Passed          â”‚ 105    â”‚ -       â”‚ -  â”‚
â”‚ Failed          â”‚ 8      â”‚ < 10    â”‚ âœ“  â”‚
â”‚ Blocked         â”‚ 2      â”‚ 0       â”‚ âœ—  â”‚
â”‚ Pass Rate       â”‚ 91.3%  â”‚ > 95%   â”‚ âœ—  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

DEFECT METRICS:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Defects Found    â”‚ 18                   â”‚
â”‚ Defects Fixed    â”‚ 15                   â”‚
â”‚ Defects Open     â”‚ 3                    â”‚
â”‚ Reopen Rate      â”‚ 2/15 = 13%          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ By Severity:                            â”‚
â”‚ Critical: 1 (fixed) | High: 5 (2 open)  â”‚
â”‚ Medium: 8 (all fixed) | Low: 4 (1 open) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

AUTOMATION METRICS:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Total Test Cases     â”‚ 300              â”‚
â”‚ Automated            â”‚ 195 (65%)        â”‚
â”‚ Sprint New Auto      â”‚ +15              â”‚
â”‚ Automation Pass Rate â”‚ 98%              â”‚
â”‚ Execution Time       â”‚ 45 min           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

SPRINT VELOCITY:
Planned: 45 points | Completed: 42 points
Velocity: 42 (vs 40 last sprint â†’ +5%)

RECOMMENDATIONS:
1. Address 2 blocked test cases (env issue)
2. Fix 2 open High severity bugs before release
3. Increase automation to 70% next sprint`
        },
        agileJiraExample: {
          context: "Configure Jira dashboards to auto-generate test metrics.",
          realWorldScenario: "QA dashboard shows real-time pass rate, defect trends, and sprint burndown.",
          sampleDocument: `JIRA QA DASHBOARD CONFIGURATION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

DASHBOARD: QA Sprint Metrics

GADGETS:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. TEST EXECUTION PIE CHART             â”‚
â”‚    Filter: type = "Test Case"           â”‚
â”‚            AND Sprint = activeSprint()  â”‚
â”‚    Group by: Execution Status           â”‚
â”‚                                         â”‚
â”‚    Display:                             â”‚
â”‚    ğŸŸ¢ Passed: 105 (91%)                 â”‚
â”‚    ğŸ”´ Failed: 8 (7%)                    â”‚
â”‚    ğŸŸ¡ Blocked: 2 (2%)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. DEFECT SEVERITY DISTRIBUTION         â”‚
â”‚    Filter: type = Bug                   â”‚
â”‚            AND Sprint = activeSprint()  â”‚
â”‚    Group by: Severity                   â”‚
â”‚                                         â”‚
â”‚    Display:                             â”‚
â”‚    ğŸ”´ Critical: â–ˆâ–ˆ 1                    â”‚
â”‚    ğŸŸ  High: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 5                     â”‚
â”‚    ğŸŸ¡ Medium: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 8                â”‚
â”‚    ğŸŸ¢ Low: â–ˆâ–ˆâ–ˆâ–ˆ 4                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. BURNDOWN CHART                       â”‚
â”‚    Y: Story Points Remaining            â”‚
â”‚    X: Sprint Days                       â”‚
â”‚                                         â”‚
â”‚    Shows: Actual vs Ideal burndown      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. DEFECT TREND (Created vs Resolved)   â”‚
â”‚    Period: Last 5 sprints               â”‚
â”‚                                         â”‚
â”‚    Sprint 11: 15/12 (Gap: +3)           â”‚
â”‚    Sprint 12: 18/20 (Gap: -2)           â”‚
â”‚    Sprint 13: 14/15 (Gap: -1)           â”‚
â”‚    Sprint 14: 16/14 (Gap: +2)           â”‚
â”‚    Sprint 15: 18/15 (Gap: +3) âš ï¸        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`
        },
        tips: [
          "Focus on actionable metrics, not vanity metrics",
          "Always compare against targets/trends",
          "Know how to calculate each metric"
        ],
        commonMistakes: [
          "Tracking too many metrics",
          "Not acting on metric insights",
          "Missing trend analysis"
        ],
        followUpQuestions: [
          "What's more important: pass rate or coverage?",
          "How do you handle metric gaming?",
          "What metrics indicate team health?"
        ],
        difficulty: "Intermediate"
      }
    ]
  }
];

// Quick reference for common interview questions
export const quickReferenceQuestions = [
  "What is STLC?",
  "Difference between Smoke and Regression testing?",
  "How do you write a test case?",
  "What is BVA and EP?",
  "Explain Agile ceremonies",
  "What is Definition of Done?",
  "How do you prioritize test cases?",
  "What metrics do you track?",
  "How do you handle flaky tests?",
  "What is API testing?"
];

export const interviewTips = {
  preparation: [
    "Review your project experience and prepare specific examples",
    "Practice STAR method for behavioral questions",
    "Know the tools and technologies on your resume",
    "Prepare questions to ask the interviewer"
  ],
  during: [
    "Listen carefully to the full question before answering",
    "Ask for clarification if needed",
    "Use specific examples from your experience",
    "Be honest about what you don't know"
  ],
  common: [
    "Keep answers concise - 2-3 minutes max",
    "Quantify your achievements when possible",
    "Show enthusiasm for testing and quality",
    "Relate answers to the company's domain/products"
  ]
};
